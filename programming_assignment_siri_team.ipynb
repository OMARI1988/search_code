{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siri task\n",
    "\n",
    "In this task ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Siri Trie class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#=------------------------------------------------------=#\n",
    "## A Trie is defined as ...\n",
    "\n",
    "## This class is used to:\n",
    "## 1- add and keep concepts\n",
    "## 2- seach sentences and return the found concepts\n",
    "## 3- save and load previously defined concept Tries\n",
    "class Siri_Trie:\n",
    "    #=--------------------------------------------------=#\n",
    "    def __init__(self):\n",
    "        # the start of the Trie\n",
    "        self.head = {}\n",
    "        \n",
    "        # the maximum len of n_grams for your concepts (will be updated automatically)\n",
    "        self.n_gram = 1\n",
    "\n",
    "    #=--------------------------------------------------=#\n",
    "    ## This function adds new words to the Trie\n",
    "    def add_concept(self, concept):\n",
    "        \n",
    "        # clean the concept\n",
    "        concept = self._clean(concept)\n",
    "        \n",
    "        # loop through the characters in the concept and add them to the Trie\n",
    "        cur = self.head\n",
    "        for ch in concept:\n",
    "            if ch not in cur:   cur[ch] = {}\n",
    "            cur = cur[ch]\n",
    "        \n",
    "        # I use a double dot (..) to indicate the end of a word at this character\n",
    "        cur['..'] = True\n",
    "        \n",
    "        # update the n_gram maximum len\n",
    "        if self.n_gram < len(concept.split()): \n",
    "            self.n_gram = len(concept.split())\n",
    "            \n",
    "    #=--------------------------------------------------=#\n",
    "    ## This function is used to clean \n",
    "    def _clean(self, concept):\n",
    "    \n",
    "        # remove non-ascii characters (helps reduce errors)\n",
    "        pass\n",
    "    \n",
    "        # lower case the concept (inferred from the task description)\n",
    "        pass\n",
    "        \n",
    "        # remove all punctuation (as requested by the task description)\n",
    "        pass\n",
    "        \n",
    "        # remove all white spaces\n",
    "        concept = \" \".join(concept.split())\n",
    "        \n",
    "        return concept\n",
    "        \n",
    "    #=--------------------------------------------------=#\n",
    "    ## This function searches the Trie for a given concept\n",
    "    def search_n_gram(self, word):\n",
    "        \n",
    "        # perform the search character by character starting from the Trie head\n",
    "        cur = self.head\n",
    "        for ch in word:\n",
    "            # if no concept contains this sequence of characters, stop searching\n",
    "            if ch not in cur:\n",
    "                return False\n",
    "            cur = cur[ch]\n",
    "\n",
    "        # if there is a concept that contains the sequence of characters and ends with this character \n",
    "        if '..' in cur:\n",
    "            return True\n",
    "        # if no concept ends with character\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    #=--------------------------------------------------=#\n",
    "    ## This function searches a given sentences and return the mentioned concepts\n",
    "    def search(self, sentence):\n",
    "        \n",
    "        # clean sentence\n",
    "        sentence = self._clean(sentence)\n",
    "        \n",
    "        # create n_grams (the n is decided based on the longest available concept in the Trie)\n",
    "        tokens = sentence.split(' ')\n",
    "        n_grams = set([' '.join(tokens[i:i+j+1]) for j in range(np.min([self.n_gram, len(tokens)])) for i in range(len(tokens))])\n",
    "        \n",
    "        # search every n-gram\n",
    "        concepts = [n_gram for n_gram in n_grams if self.search_n_gram(n_gram)]\n",
    "        \n",
    "        return sorted(concepts)\n",
    "    \n",
    "    #=--------------------------------------------------=#\n",
    "    ## This functions saves a Trie to disk\n",
    "    def save(self, dir_):\n",
    "        \n",
    "        # make sure directory exists\n",
    "        pass\n",
    "    \n",
    "        # save the Trie\n",
    "        pass\n",
    "\n",
    "    #=--------------------------------------------------=#   \n",
    "    ## This function loads a Trie from disk\n",
    "    def load(self, file_):\n",
    "        \n",
    "        # make sure directory exists\n",
    "        pass\n",
    "    \n",
    "        # make sure file exists\n",
    "        pass\n",
    "    \n",
    "        # try to read file\n",
    "        try:\n",
    "            pass\n",
    "        except:\n",
    "            print('Could not read the file: {file_}')\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Siri Trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi']\n",
      "['hello sir', 'hi']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "ask_siri = Siri_Trie()\n",
    "\n",
    "ask_siri.add_concept(\"hi\")\n",
    "ask_siri.add_concept(\"hello sir\")\n",
    "print(ask_siri.search(\"hi\"))\n",
    "print(ask_siri.search(\"hello sir this is me hi\"))\n",
    "print(ask_siri.search(\"hello\"))\n",
    "print(ask_siri.search(\"hey\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import igraph\n",
    "# # print(igraph.__version__)\n",
    "\n",
    "# from igraph import *\n",
    "\n",
    "# class Siri_Trie_graph:\n",
    "#     def __init__(self):\n",
    "#         self.c = 0  # counter\n",
    "#         self.g = Graph()  # the graph of characters\n",
    "#         self.g.add_vertices(0)\n",
    "        \n",
    "        \n",
    "#     ## This function adds new words to the dictionary\n",
    "#     def add(self, word):\n",
    "#         print(self.g)\n",
    "#         for ch in word:\n",
    "#             print(ch)\n",
    "        \n",
    "# #         cur = self.head\n",
    "# #         for ch in word:\n",
    "# #             if ch not in cur:   cur[ch] = {}\n",
    "# #             cur = cur[ch]\n",
    "# #         # I use the .. to indicate the end of a word at this character\n",
    "# #         # The use of a double dot (..) is based on the fact that we only use one char at a time\n",
    "# #         # so there can be no two dots, which prevents the mis-classification of the end of a word\n",
    "# #         cur['..'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#You can assume that there will be at most 20 words in the input string and that the words are \n",
    "# separated by one or more whitespace characters. Any punctuation in the input should be treated \n",
    "# as not significant.\n",
    "\n",
    "\n",
    "# The use of a double dot (..) is based on the fact that we only use one char at a time\n",
    "# so there can be no two dots, which prevents the mis-classification of the end of a word.\n",
    "        \n",
    "# Note that the list of concepts to check against could run into the millions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please return your solution in the form of an archive (zip, tar etc.). When submitting please\n",
    "# return all your code (including any automated tests you might have developed) along with\n",
    "# documentation you feel might be appropriate. It should be easy for us to compile, run and verify\n",
    "# the correctness of your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to estimate the computational complexity of your\n",
    "# solution and indicate this in your documentation. You should also briefly highlight any aspects\n",
    "# that could affect accuracy, speed, scalability or reliability of your solution should it be taken into\n",
    "# a live production environment.\n",
    "\n",
    "# https://www.youtube.com/watch?v=o6563NNbdtg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
